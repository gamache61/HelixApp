<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
<title>Helix AI (Gemini 2.5)</title>

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="theme-color" content="#000000">

<style>
  /* --- LAYOUT --- */
  body { 
    background: #000; 
    color: #fff; 
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; 
    height: 100vh; 
    margin: 0; 
    display: flex; 
    flex-direction: column; 
    overflow: hidden; 
  }
   
  /* --- SCENE (ORB) --- */
  #scene { 
    flex: 1; 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    background: radial-gradient(circle at center, #1a1a1a 0%, #000 100%); 
    position: relative; 
    border-bottom: 1px solid #333; 
  }
  
  #core { 
    width: 110px; 
    height: 110px; 
    background: radial-gradient(circle at 30% 30%, #fff, #0ff, #001); 
    border-radius: 50%; 
    box-shadow: 0 0 30px cyan; 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    position: relative; 
    z-index: 2; 
    transition: 0.3s; 
  }
  #core span { 
    font-size: 10px; 
    font-weight: 900; 
    letter-spacing: 2px; 
    color: rgba(0,0,0,0.7); 
    pointer-events: none; 
    font-family: monospace; 
  }
  
  /* ANIMATIONS */
  #core.talking { background: #a0f; box-shadow: 0 0 80px #a0f; animation: pulse 0.4s alternate infinite; }
  #core.thinking { background: #fb0; box-shadow: 0 0 60px orange; transform: scale(0.95); }
  #core.listening { background: #0f0; box-shadow: 0 0 60px lime; }
  
  @keyframes pulse { 0% { transform: scale(1); } 100% { transform: scale(1.15); } }

  /* --- CAMERA OVERLAY --- */
  #camera-container { 
    display: none; 
    position: absolute; 
    top: 0; left: 0; 
    width: 100%; height: 100%; 
    background: #000; 
    z-index: 10; 
    flex-direction: column; 
    justify-content: center; 
    align-items: center; 
  }
  video { width: 100%; height: 100%; object-fit: cover; }
  #cam-overlay { 
    position: absolute; 
    bottom: 30px; 
    background: rgba(0,0,0,0.6); 
    padding: 8px 15px; 
    border-radius: 20px; 
    font-family: monospace; 
    font-size: 14px; 
    color: cyan; 
    pointer-events: none; 
    border: 1px solid cyan;
  }

  /* --- CHAT CONSOLE --- */
  #console { 
    height: 40%; 
    overflow-y: auto; 
    padding: 20px; 
    background: #0a0a0a; 
    display: flex; 
    flex-direction: column; 
    gap: 12px; 
    scroll-behavior: smooth;
  }
  .msg { padding: 12px 16px; border-radius: 12px; font-size: 15px; max-width: 85%; line-height: 1.5; }
  .user { align-self: flex-end; background: #222; color: #fff; border: 1px solid #333; }
  .ai { align-self: flex-start; background: #111; color: #ccc; border: 1px solid #333; }
  .sys { align-self: center; font-size: 12px; color: #666; font-style: italic; margin: 10px 0; }

  /* --- CONTROLS --- */
  #controls { 
    display: flex; 
    flex-direction: column; 
    gap: 10px; 
    padding: 15px; 
    background: #000; 
    border-top: 1px solid #333; 
  }
  #input-row { display: flex; gap: 10px; }
  
  #txt-input { 
    flex-grow: 1; 
    padding: 15px; 
    border-radius: 8px; 
    border: 1px solid #333; 
    background: #111; 
    color: white; 
    font-size: 16px; 
    outline: none; 
  }
  #txt-input:focus { border-color: cyan; }

  button { 
    background: #222; 
    color: cyan; 
    border: 1px solid #333; 
    border-radius: 8px; 
    font-size: 18px; 
    cursor: pointer; 
    padding: 0 20px; 
    transition: 0.2s; 
  }
  button:active { transform: scale(0.95); }
  
  #mic-btn { 
    padding: 15px; 
    font-weight: bold; 
    width: 100%; 
    color: #fff; 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    gap: 10px; 
  }
  #mic-btn.active { background: #060; border-color: lime; box-shadow: 0 0 15px #060; }
</style>
</head>
<body>

<div id="scene">
    <div id="core"><span id="orb-text">HELIX</span></div>
    
    <div id="camera-container" onclick="snapPhoto()">
        <video id="cam-feed" autoplay playsinline></video>
        <div id="cam-overlay">TAP SCREEN TO CAPTURE</div>
    </div>
</div>

<div id="console"></div>

<div id="controls">
    <div id="input-row">
        <button onclick="startCamera()">üì∑</button>
        <input id="txt-input" placeholder="Type message..." onkeydown="if(event.key==='Enter') sendText()">
        <button onclick="sendText()">‚û§</button>
    </div>
    <button id="mic-btn" onclick="handleMicClick()">üéôÔ∏è TAP TO SPEAK</button>
</div>

<canvas id="cam-canvas" style="display:none;"></canvas>

<script>
// ==============================================================================
// üü¢ CONFIGURATION (YOUR KEYS ARE SET HERE)
// ==============================================================================

const GOOGLE_KEY = "AIzaSyCr6c1MGUHygHb74j1CV1VHBEApFK5SPJM";
const ELEVEN_KEY = "e270a037075fafc2f00f56b6f3148de92802dac819a990274d4e8bdc8fa3435a";

// ==============================================================================

const MODEL_ID = "gemini-2.5-flash"; // Using the latest 2.5 Flash model
const VOICE_ID = "21m00Tcm4TlvDq8ikWAM"; // Rachel Voice

let history = [];
let isSpeaking = false;
let recognition = null;
let synth = window.speechSynthesis;
let currentImage = null;

// --- INITIALIZATION ---
window.onload = () => {
    addMessage('ai', "Helix Online. Running Gemini 2.5 Flash.");
};

// --- ORB VISUALS ---
function updateOrb(state, text) {
    const orb = document.getElementById('core');
    const label = document.getElementById('orb-text');
    orb.className = state;
    if(text) label.innerText = text;
}

// --- SEND MESSAGE LOGIC ---
async function sendText() {
    let input = document.getElementById('txt-input');
    let text = input.value.trim();
    
    if (!text && !currentImage) return;
    
    input.value = "";
    addMessage('user', text || "[Image Sent]");
    updateOrb('thinking', 'THINKING');
    
    // 1. Build the Message Payload
    let userContent = { role: 'user', parts: [] };
    
    if(text) {
        userContent.parts.push({ text: text });
    }
    
    if(currentImage) {
        userContent.parts.push({ 
            inline_data: { mime_type: "image/jpeg", data: currentImage } 
        });
        currentImage = null; // Reset image after sending
    }
    
    history.push(userContent);
    
    // 2. Manage History (Keep last 15 turns)
    if(history.length > 15) history = history.slice(-15);

    try {
        // 3. Call Google Gemini API
        let response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${MODEL_ID}:generateContent?key=${GOOGLE_KEY}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ contents: history })
        });
        
        let data = await response.json();
        
        if(data.error) {
            console.error("Gemini Error:", data.error);
            throw new Error(data.error.message);
        }
        
        let ans = data.candidates[0].content.parts[0].text;
        
        // 4. Save AI Response
        history.push({ role: 'model', parts: [{ text: ans }] });
        
        addMessage('ai', ans);
        speak(ans);

    } catch(e) {
        addMessage('sys', "Error: " + e.message);
        updateOrb('', 'ERROR');
        speak("I encountered an error connecting to the model.");
    }
}

// --- ELEVENLABS VOICE ENGINE ---
async function speak(text) {
    if(!text) return;
    
    // Clean text (remove markdown like * or # for smoother speech)
    let cleanText = text.replace(/[*#`]/g, '').slice(0, 450); // Limit length for speed
    
    isSpeaking = true;
    updateOrb('talking', 'SPEAKING');

    try {
        const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
            method: "POST",
            headers: { 
                "xi-api-key": ELEVEN_KEY, 
                "Content-Type": "application/json" 
            },
            body: JSON.stringify({ 
                text: cleanText, 
                model_id: "eleven_multilingual_v2", // High Quality V2 Model
                voice_settings: { stability: 0.5, similarity_boost: 0.75 } 
            })
        });

        if(!response.ok) {
            let errText = await response.text();
            console.warn("ElevenLabs Error:", errText);
            throw new Error("Voice Generation Failed");
        }

        const audioBlob = await response.blob();
        const audio = new Audio(URL.createObjectURL(audioBlob));
        
        audio.onended = () => { 
            isSpeaking = false; 
            updateOrb('', 'HELIX'); 
        };
        
        await audio.play();

    } catch(e) {
        console.log("Falling back to system voice...");
        let u = new SpeechSynthesisUtterance(cleanText);
        u.onend = () => { isSpeaking = false; updateOrb('', 'HELIX'); };
        synth.speak(u);
    }
}

// --- HELPER: ADD MESSAGE ---
function addMessage(role, text) {
    let d = document.createElement('div');
    d.className = 'msg ' + role;
    
    // Simple markdown formatting
    if(role === 'ai') {
        // Bold
        text = text.replace(/\*\*(.*?)\*\*/g, '<b>$1</b>');
        // Code blocks
        if(text.includes("```")) {
            text = text.replace(/```([\s\S]*?)```/g, '<pre style="background:#222; padding:10px; border-radius:5px; overflow-x:auto;">$1</pre>');
        }
    }
    
    d.innerHTML = text;
    let c = document.getElementById('console');
    c.appendChild(d);
    c.scrollTop = c.scrollHeight;
}

// --- MICROPHONE INPUT ---
if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.lang = 'en-US';
    recognition.continuous = false;
    
    recognition.onstart = () => {
        updateOrb('listening', 'LISTENING');
        document.getElementById('mic-btn').classList.add('active');
        document.getElementById('mic-btn').innerText = "üõë LISTENING...";
    };

    recognition.onresult = (e) => { 
        let transcript = e.results[0][0].transcript;
        document.getElementById('txt-input').value = transcript;
        sendText();
    };
    
    recognition.onend = () => {
        document.getElementById('mic-btn').classList.remove('active');
        document.getElementById('mic-btn').innerHTML = "üéôÔ∏è TAP TO SPEAK";
        if(!isSpeaking) updateOrb('', 'HELIX');
    };
}

function handleMicClick() {
    if (!recognition) return alert("Microphone not supported in this browser.");
    
    // Unlock audio context for mobile
    let u = new SpeechSynthesisUtterance("");
    synth.speak(u);

    document.getElementById('mic-btn').classList.add('active');
    recognition.start();
}

// --- CAMERA INPUT ---
async function startCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { facingMode: "environment" } 
        });
        const video = document.getElementById('cam-feed');
        video.srcObject = stream;
        document.getElementById('camera-container').style.display = 'flex';
    } catch(e) { 
        alert("Camera Error: " + e.message); 
    }
}

function snapPhoto() {
    const video = document.getElementById('cam-feed');
    const canvas = document.getElementById('cam-canvas');
    
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    canvas.getContext('2d').drawImage(video, 0, 0);
    
    // Convert to Base64 (remove data:image/jpeg;base64, prefix)
    currentImage = canvas.toDataURL('image/jpeg').split(',')[1];
    
    // Stop Camera
    video.srcObject.getTracks().forEach(t => t.stop());
    document.getElementById('camera-container').style.display = 'none';
    
    addMessage('sys', "üì∑ Image Captured. Type a message or speak to send it.");
}
</script>
</body>
</html>